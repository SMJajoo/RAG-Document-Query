{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f37dca-3541-40cc-aa6c-c39640064d01",
   "metadata": {},
   "source": [
    "# Create an LLM Agent Capable of Math and Machine Learning Operations, Using the OpenAI API.\n",
    "\n",
    "You are an AI engineer working at a financial services firm. Your financial analysts want to use modern large language models as a tool, but need access to mathematical and regression tools that LLMâ€™s are not natively skilled at. Your manager has asked you to prototype an LLM agent solution, coding directly against the OpenAI chat completions API, that augments a chatbot with local tools capable of performing basic mathematical operations and linear regression. Your LLM agent will be evaluated by its ability to successfully compute math and regression problems given as natural language prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f537a925-6794-4905-b80d-b4ba75226e19",
   "metadata": {},
   "source": [
    "# Write a function to serve a math tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d6e977-cb23-4be3-92e3-bdd1672f2432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def perform_math_operation(operation, args=[]):\n",
    "    result = 0\n",
    "    if operation == 'add':\n",
    "        result = sum(args)\n",
    "    elif operation == 'subtract':\n",
    "        result = args[0] - sum(args[1:])\n",
    "    elif operation == 'multiply':\n",
    "        result = 1\n",
    "        for num in args:\n",
    "            result *= num\n",
    "    elif operation == 'divide':\n",
    "        result = args[0]\n",
    "        for num in args[1:]:\n",
    "            result /= num\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported operation\")\n",
    " \n",
    "    retval = {\"Result\": result}\n",
    "    return json.dumps(retval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea3f29c-8d48-445e-901b-452dca78d85b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Result\": 32}'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perform_math_operation(\"multiply\", [8,2,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace7a4c8-bb80-4dba-9ca3-06539a17da50",
   "metadata": {},
   "source": [
    "# Write a function to serve as a Linear Regression Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd55bd-bd25-43fd-913e-77c1f97edbab",
   "metadata": {},
   "source": [
    "Implement a Python function that may be used by an LLM agent to predict the next value in a series of numbers, using linear regression.  This function will accept a single argument that is a list of numeric values in a series, and will return the predicted next value in JSON format, labeled as Next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a6a0f9a-28cc-4b69-aa45-d06310ce26ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    " \n",
    "def predict_next_in_series(series):\n",
    "    x = np.array(range(len(series))).reshape(-1, 1)\n",
    "    y = np.array(series).reshape(-1, 1)\n",
    "    model = LinearRegression().fit(x, y)\n",
    "    next_index = len(series)\n",
    "    next_value = model.predict([[next_index]])\n",
    "    next_info = {\n",
    "        \"Next value\": next_value[0][0]\n",
    "    }\n",
    "    return json.dumps(next_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "571e9d1a-e7be-4c91-b68d-402c8d200c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"Next value\": 10.0}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_next_in_series([2, 4, 6, 8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5ffbb-900b-4088-8b67-13043575f9e2",
   "metadata": {},
   "source": [
    "# Create JSON Schema Objects For Our Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff5bd9f-5923-4e20-bf4f-3f05c2c20032",
   "metadata": {},
   "source": [
    "Our math and regression tools must be defined for the OpenAI Chat Completions API, in their documented format that includes a JSON Schema definition for the properties of the arguments our tools accept (under parameters,) a name for each function (under name,) and a description of the circumstances under which this tool should be used (under description.) Create definitions for both the mathematical operations tool and linear regression tool functions, and combine them both into a list named tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09e3f03b-bdd0-413c-9989-bee3cacd4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mathTool = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"perform_math_operation\",\n",
    "            \"description\": \"Perform a mathematical operation\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"operation\": \n",
    "                    {\n",
    "                        \"type\": \"string\", \n",
    "                        \"enum\": [\"add\", \"subtract\", \"multiply\", \"divide\"],\n",
    "                        \"description\": \"The requested mathematical operation to perform.\"\n",
    "                    },\n",
    "                    \"operands\": \n",
    "                    {\n",
    "                        \"type\": \"array\", \n",
    "                        \"items\": {\"type\": \"number\"},\n",
    "                        \"description\": \"The operands of the requested mathematical operation, from left to right.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"operation\", \"operands\"]\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "\n",
    "regressionTool = {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"predict_next_in_series\",\n",
    "            \"description\": \"Predict the next number in a series using linear regression\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"series\": {\n",
    "                        \"type\": \"array\", \n",
    "                        \"items\": {\"type\": \"number\"},\n",
    "                        \"description\": \"The list of numbers in the series to be completed.\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"series\"]\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8f080b8-5097-4cff-a8c1-3d36b8526f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [mathTool, regressionTool]\n",
    "# tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d395e14-8ab7-4ea2-b541-f70e6275b06a",
   "metadata": {},
   "source": [
    "# Invoke OpenAI chat Completions API with Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5a8b71-44de-4686-8c3f-9fc7a71d7468",
   "metadata": {},
   "source": [
    "Use the OpenAI Chat Completions API to answer a given prompt as a parameter to a function named llm_agent, given a pre-defined list of tools it may use at its discretion for performing math operations, or predicting the next value in a series. If the chat completions API call returns one or more requested tool calls, invoke the appropriate function(s) to execute the tool(s), append their result to the chat messages, and call the Chat Completions API again for a final response including the tool output. Use the gpt-3.5-turbo-0613 model. Incorporate print calls indicating when each step is executed to be used for debugging and validation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f136cb36-4c71-4054-8ce1-27080a8544cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from openai import OpenAI\n",
    " \n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee613a3f-8696-41c4-8621-ecfc69a586ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to dispatch an initial chat completions request together with the available tools\n",
    "def make_initial_request(messages):\n",
    " \n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=None\n",
    "    )\n",
    "    \n",
    "    response_message = response.choices[0].message\n",
    "    \n",
    "    # print('response_message: ',response_message)\n",
    "    \n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ae5443b-f062-4a49-8848-b467e17a8ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to invoke one or more defined tool functions, and return a response in OpenAI's required format\n",
    "def call_tool(tool):\n",
    "    \n",
    "    # print(\"calling tool: \")\n",
    "    # print(tool)\n",
    "    \n",
    "    response = {}\n",
    "    \n",
    "    function_name = tool.function.name\n",
    "    if (function_name == \"perform_math_operation\"):\n",
    "        args = json.loads(tool.function.arguments)\n",
    "        fn_response = perform_math_operation(operation=args.get(\"operation\"),args=args.get(\"operands\"))\n",
    "        response = {\n",
    "            \"tool_call_id\": tool.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": fn_response,\n",
    "        }\n",
    "    elif (function_name == \"predict_next_in_series\"):\n",
    "        args = json.loads(tool.function.arguments)\n",
    "        fn_response = predict_next_in_series(series=args.get(\"series\"))\n",
    "        response = {\n",
    "            \"tool_call_id\": tool.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": function_name,\n",
    "            \"content\": fn_response,\n",
    "        }\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "031a72fc-dbca-4e2e-a216-9abc08350bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to accept a given prompt, call any requested tools from the chat completions API, append their result(s) to the message chain, and perform a second chat completions call if necessary:\n",
    "\n",
    "def llm_agent(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    first_response = make_initial_request(messages)\n",
    "    \n",
    "    tool_calls = first_response.tool_calls\n",
    "    if (tool_calls):\n",
    " \n",
    "        messages.append(first_response)\n",
    "        \n",
    "        for tool in tool_calls:\n",
    "            tool_response = call_tool(tool)\n",
    "            messages.append(tool_response)\n",
    " \n",
    "        # print(\"second call: \")\n",
    "        # print(messages)\n",
    "        second_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo-0613\",\n",
    "            messages = messages,\n",
    "        )\n",
    "            \n",
    "        return second_response\n",
    "    else:\n",
    "        return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8588d95e-ea3a-4fd9-be29-9daa2104ba8b",
   "metadata": {},
   "source": [
    "# Test the resulting LLM Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e465f070-c008-4917-8a0f-d4bae8630d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second call: \n",
      "ChatCompletion(id=None, choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='5 divided by 3 is approximately 1.67', role='assistant', function_call=None, tool_calls=[], name=''))], created=None, model=None, object=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=64, total_tokens=75), failure_reason='', status='STATUS_SUCCESS')\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is 5 divided by 3?\"\n",
    "print (llm_agent(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ca4561d5-211e-462d-93b4-98995c3f4de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id=None, choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The next value in the series 1, 3, 5, 7, 11 is 12.6 (rounded to one decimal place).', role='assistant', function_call=None, tool_calls=[], name=''))], created=None, model=None, object=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=32, prompt_tokens=81, total_tokens=113), failure_reason='', status='STATUS_SUCCESS')\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is the next value in the series 1, 3, 5, 7, 11?\"\n",
    "print (llm_agent(prompt))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
